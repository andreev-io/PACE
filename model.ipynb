{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7635ebcf-72d0-4401-a8f1-30c209378284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import datetime\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63172a0b-e8d6-4334-a41d-7d49155b9f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca607a3-4d07-4e3e-8f40-c65c2afd40e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d667d28-8c3f-4f9d-ab39-eca008a4855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_easy_tasks(model, x, mask, y, N, K, epoch):\n",
    "    criterion = nn.BCELoss(reduction='none')\n",
    "    model.train(False)\n",
    "    y_hat = model(x, mask)\n",
    "\n",
    "    # Pick tasks in the batch for which the loss is less than 1 / N.\n",
    "    loss = torch.add((1 / GAMMA) * criterion(y_hat, y), -1 / N)\n",
    "    easy_indices = list((loss < 0).nonzero()) if epoch >= K else list(loss.nonzero())\n",
    "    print(f\"indices picked: {len(easy_indices)}, K: {K}, epoch: {epoch}\")\n",
    "\n",
    "    easy_timeseries = torch.empty((len(easy_indices), x.size()[1], x.size()[2]))\n",
    "    easy_masks = torch.empty((len(easy_indices), x.size()[1], x.size()[2]))\n",
    "    easy_labels = torch.empty((len(easy_indices),))\n",
    "\n",
    "    for i, index in enumerate(easy_indices):\n",
    "        index = index.item()\n",
    "        easy_timeseries[i] = x[index]\n",
    "        easy_masks[i] = mask[index]\n",
    "        easy_labels[i] = y[index]\n",
    "\n",
    "    model.train(True)\n",
    "    return torch.Tensor(easy_timeseries).to(device), torch.Tensor(easy_masks).to(device), torch.Tensor(easy_labels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cac9b9-7b0a-41b1-8216-b0e4e852d452",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/lvl2_train.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f).sort_values(['subject_id', 'hadm_id', 'icustay_id'])\n",
    "\n",
    "with open(\"data/Ys_train.pkl\", \"rb\") as f:\n",
    "    labels = pickle.load(f).sort_values(['subject_id', 'hadm_id', 'icustay_id'])\n",
    "    \n",
    "data = data.reset_index(drop=True).droplevel(level=\"LEVEL2\", axis=1)\n",
    "features = data[\"mean\"].to_numpy()\n",
    "masks = data[\"mask\"].to_numpy()\n",
    "\n",
    "features = np.split(features, [48 * i for i in range(1, len(features) // 48)])\n",
    "masks = np.split(masks, [48 * i for i in range(1, len(masks) // 48)])\n",
    "\n",
    "features = torch.tensor(features, dtype=torch.float).to(device)\n",
    "masks = torch.tensor(masks, dtype=torch.float).to(device)\n",
    "labels = torch.squeeze(torch.tensor(labels.to_numpy(), dtype=torch.float).to(device))\n",
    "\n",
    "print(f\"Shape of features: {features.size()}\")\n",
    "print(f\"Shape of masks: {masks.size()}\")\n",
    "print(f\"Shape of labels: {labels.size()}\")\n",
    "assert len(features) == len(labels)\n",
    "assert features.size() == masks.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab338ea2-8610-40ed-87aa-210e368df325",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [int(round(len(features) * 8 / 10)), int(round(len(features) / 10)), int(round(len(features) / 10))]\n",
    "splits = [lengths[0], lengths[0] + lengths[1]]\n",
    "\n",
    "train_features = features[0:splits[0]]\n",
    "train_masks = masks[0:splits[0]]\n",
    "train_labels = labels[0:splits[0]]\n",
    "\n",
    "def create_easy_train_dataloader(model, N, K, epoch):\n",
    "    easy_timeseries, easy_masks, easy_labels = pick_easy_tasks(model, train_features, train_masks, train_labels, N, K, epoch)\n",
    "    easy_train_dataset = TensorDataset(easy_timeseries, easy_masks, easy_labels)\n",
    "    if len(easy_train_dataset) == 0:\n",
    "        return None, len(train_features)\n",
    "    return DataLoader(easy_train_dataset, batch_size=32, shuffle=True), len(train_features)\n",
    "\n",
    "test_dataset = TensorDataset(features[splits[0]:splits[1]], masks[splits[0]:splits[1]], labels[splits[0]:splits[1]])\n",
    "validation_dataset = TensorDataset(features[splits[1]:], masks[splits[1]:], labels[splits[1]:])\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=len(validation_dataset), shuffle=False)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_features)} ICU stays with 48-hour timeseries for {features.size()[2]} measurements each\")\n",
    "print(f\"Test dataset size: {len(test_dataset)} ICU stays with 48-hour timeseries for {features.size()[2]} measurements each\")\n",
    "print(f\"Validation dataset size: {len(validation_dataset)} ICU stays with 48-hour timeseries for {features.size()[2]} measurements each\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacdfe67-c25f-4bf9-9f0f-6b6137173db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "constant_classifier = DummyClassifier(strategy=\"constant\", constant=1)\n",
    "uniform_classifier = DummyClassifier(strategy=\"uniform\")\n",
    "\n",
    "inputs, labels = None, None\n",
    "for inp, mask, lab in validation_dataloader:\n",
    "    inputs, labels = inp, lab\n",
    "    labels = labels.clone().cpu().detach()\n",
    "\n",
    "constant_classifier.fit([0] * len(labels), labels)\n",
    "uniform_classifier.fit([0] * len(labels), labels)\n",
    "y_constant = constant_classifier.predict([0] * len(labels))\n",
    "y_uniform = uniform_classifier.predict([0] * len(labels))\n",
    "\n",
    "print(f\"Baseline F1 score constant 1: {f1_score(labels, y_constant)}\")\n",
    "print(f\"Baseline F1 score uniform: {f1_score(labels, y_uniform)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd26fc87-1982-4e16-9f41-142e0c57d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.5\n",
    "N = 16\n",
    "LAMBDA = 1.3\n",
    "LR = 0.001\n",
    "OMEGA = 0.001\n",
    "K = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48d7e17-b9bb-41f0-b4f4-73e8dda0a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn\n",
    "\n",
    "class TinyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "        self.rnn = nn.GRU(input_size=104, hidden_size=32, num_layers=1, bidirectional=False, batch_first=True)\n",
    "        self.fc1 = nn.Linear(in_features=32, out_features=1)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        try:\n",
    "            x = x * mask\n",
    "        except:\n",
    "            print(x, mask)\n",
    "        _, h_n = self.rnn(x)\n",
    "        fc1_out = self.fc1(torch.squeeze(h_n))\n",
    "        # Multiply prediction value before sigmoid activation by gamma.\n",
    "        # This is part of the micro framework.\n",
    "        r = torch.mul(fc1_out, GAMMA)\n",
    "        res = torch.sigmoid(r)\n",
    "        return torch.squeeze(res)\n",
    "\n",
    "tinymodel = TinyModel()\n",
    "tinymodel.to(device)\n",
    "\n",
    "print('The model:')\n",
    "print(tinymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae80b486-c86a-41e7-947c-87afbf624ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(tinymodel.parameters(), LR)\n",
    "\n",
    "def loss_func(y_hat, y, model):\n",
    "    # Add a dimension when there is only one item in the batch.     \n",
    "    if len(y_hat.size()) == 0:\n",
    "        y_hat = torch.unsqueeze(y_hat, dim=0)\n",
    "\n",
    "    l1 = OMEGA * sum(p.abs().sum() for p in model.parameters())\n",
    "    cr = (1 / GAMMA) * criterion(y_hat, y)\n",
    "    \n",
    "    # Calculate the loss. The regularization is just an l1 regularization with a coefficient.\n",
    "    # The criterion is the binary cross-entropy multiplied by 1 / GAMMA, a part of the micro framework.\n",
    "    return l1 + cr\n",
    "\n",
    "    # The paper also says to subtract batch_size / N, but this value is different for different batches depending\n",
    "    # on the number of easy tasks in the batch, making it hard to compare loss across batches. Crucially, this \n",
    "    # is confusing when you look at the loss on training data (non-full batches) vs loss on testing data (full-size batches).\n",
    "    # This makes me think that actually the paper meant that you first pick easy tasks across the entire testing set,\n",
    "    # and then split it into batches rather than split into batches first and pick easy tasks after.\n",
    "    # batch_size = y_hat.size()[0]    \n",
    "    # neg = batch_size / N\n",
    "    # return l1 + cr - neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1ea2c4-ff8c-4aec-a221-2a32c9f9b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement early stopping\n",
    "for epoch in range(16):\n",
    "    running_loss = 0.0\n",
    "    number_examples_used = 0\n",
    "    dataloader, max_num_examples = create_easy_train_dataloader(tinymodel, N, K, epoch)\n",
    "    \n",
    "    if dataloader is not None:\n",
    "        for i, (features, masks, labels) in enumerate(dataloader):\n",
    "            tinymodel.train(True)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Train on easy sequences.\n",
    "            output = tinymodel(features, masks)\n",
    "            loss = loss_func(output, labels, tinymodel)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            number_examples_used += len(features)\n",
    "            if (i + 1) % 50 == 0:\n",
    "                print(f'Epoch: [{epoch + 1}, training batch {i + 1:5d}] running training loss: {running_loss / 50:.3f}')\n",
    "                running_loss = 0.0\n",
    "    \n",
    "    running_test_loss = 0.0\n",
    "    tinymodel.train(False)\n",
    "    print(f\"In epoch {epoch + 1}, number of examples trained on is {number_examples_used} out of {max_num_examples}\")\n",
    "    for i, (test_inputs, test_masks, test_labels) in enumerate(test_dataloader):\n",
    "        test_outputs = tinymodel(test_inputs, test_masks)\n",
    "        test_loss = loss_func(test_outputs, test_labels, tinymodel)\n",
    "        running_test_loss += test_loss\n",
    "    \n",
    "    print(f\"Test loss: {running_test_loss / len(test_dataloader)}\")\n",
    "    # Decrease N by a factor of lambda and as such increase 1 / N, so increase the loss threshold that defines\n",
    "    # what tasks are considrered easy.\n",
    "    N = N / LAMBDA\n",
    "    print(f\"N is now {N}\\n\\n\")\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6592c29c-748d-4424-8949-8fb5c0df3a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "tinymodel.train(False)\n",
    "out = None\n",
    "lab = None\n",
    "for inputs, masks, labels in validation_dataloader:\n",
    "    outputs = tinymodel(inputs, masks)\n",
    "    out = outputs\n",
    "    outputs = outputs > 0.5\n",
    "    lab = labels\n",
    "    labels = labels.detach().cpu().numpy()\n",
    "    outputs = outputs.detach().cpu().numpy()\n",
    "    print(f\"F1 score: {f1_score(labels, outputs)}\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(labels, outputs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51e6675-004d-44e8-9554-4a838774891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "# Fill with real values\n",
    "preds = out.cpu().detach().numpy()\n",
    "true_labels = lab.cpu().detach().numpy()\n",
    "print(sum(true_labels))\n",
    "print(len(true_labels))\n",
    "\n",
    "confidence = 0.5 + abs(preds - 0.5)\n",
    "\n",
    "def mean(x):\n",
    "    return sum(x) / len(x)\n",
    "\n",
    "coverages = []\n",
    "calculated_metrics = []\n",
    "\n",
    "for confidence_treshold in np.arange(0.5, 1.00000000, 0.0001):\n",
    "    predicted_labels = 1.0 * (preds > 0.5)\n",
    "    \n",
    "    replace_mask = confidence < confidence_treshold\n",
    "    predicted_labels[replace_mask] = 0\n",
    "\n",
    "    coverage = mean(1.0 * (confidence > confidence_treshold))\n",
    "\n",
    "    if len(true_labels[replace_mask]) == 0 or sum(predicted_labels) == 0:\n",
    "        continue\n",
    "\n",
    "    auc = metrics.roc_auc_score(true_labels[~replace_mask], predicted_labels[~replace_mask])\n",
    "    \n",
    "    calculated_metrics.append(auc)\n",
    "    coverages.append(coverage)\n",
    "    \n",
    "plt.plot(coverages, calculated_metrics)\n",
    "plt.ylim(0, 1) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809bca14-de0c-4abc-ae57-951a28e8ea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coverages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61cfcea-38cd-430b-b2f4-dcafd2d95176",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opence-v1.5.1]",
   "language": "python",
   "name": "conda-env-opence-v1.5.1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
