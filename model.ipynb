{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7635ebcf-72d0-4401-a8f1-30c209378284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import datetime\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from imblearn.over_sampling import RandomOverSampler # conda install -c conda-forge imbalanced-learn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63172a0b-e8d6-4334-a41d-7d49155b9f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca607a3-4d07-4e3e-8f40-c65c2afd40e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d667d28-8c3f-4f9d-ab39-eca008a4855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_easy_tasks(model, x, mask, y, N, K, epoch):\n",
    "    criterion = nn.BCELoss(reduction='none')\n",
    "    model.train(False)\n",
    "    y_hat = model(x, mask)\n",
    "\n",
    "    # Pick tasks in the batch for which the loss is less than 1 / N.\n",
    "    loss = torch.add((1 / GAMMA) * criterion(y_hat, y), -1 / N)\n",
    "    easy_indices = list((loss < 0).nonzero()) if epoch >= K else list(loss.nonzero())\n",
    "\n",
    "    easy_timeseries = torch.empty((len(easy_indices), x.size()[1], x.size()[2]))\n",
    "    easy_masks = torch.empty((len(easy_indices), x.size()[1], x.size()[2]))\n",
    "    easy_labels = torch.empty((len(easy_indices),))\n",
    "\n",
    "    for i, index in enumerate(easy_indices):\n",
    "        index = index.item()\n",
    "        easy_timeseries[i] = x[index]\n",
    "        easy_masks[i] = mask[index]\n",
    "        easy_labels[i] = y[index]\n",
    "\n",
    "    print(f\"samples picked: {len(easy_indices)}, positive samples picked: {sum(easy_labels)}, K: {K}, epoch: {epoch}\")\n",
    "\n",
    "    model.train(True)\n",
    "    return torch.Tensor(easy_timeseries).to(device), torch.Tensor(easy_masks).to(device), torch.Tensor(easy_labels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cac9b9-7b0a-41b1-8216-b0e4e852d452",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/lvl2_train.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f).sort_values(['subject_id', 'hadm_id', 'icustay_id'])\n",
    "\n",
    "with open(\"data/Ys_train.pkl\", \"rb\") as f:\n",
    "    labels = pickle.load(f).sort_values(['subject_id', 'hadm_id', 'icustay_id'])\n",
    "    \n",
    "data = data.reset_index(drop=True).droplevel(level=\"LEVEL2\", axis=1)\n",
    "features = data[\"mean\"].to_numpy()\n",
    "masks = data[\"mask\"].to_numpy()\n",
    "\n",
    "features = np.split(features, [48 * i for i in range(1, len(features) // 48)])\n",
    "masks = np.split(masks, [48 * i for i in range(1, len(masks) // 48)])\n",
    "\n",
    "features = torch.tensor(features, dtype=torch.float).to(device)\n",
    "masks = torch.tensor(masks, dtype=torch.float).to(device)\n",
    "labels = torch.squeeze(torch.tensor(labels.to_numpy(), dtype=torch.float).to(device))\n",
    "\n",
    "print(f\"Shape of features: {features.size()}\")\n",
    "print(f\"Shape of masks: {masks.size()}\")\n",
    "print(f\"Shape of labels: {labels.size()}\")\n",
    "assert len(features) == len(labels)\n",
    "assert features.size() == masks.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9044a1b-216c-4dfc-8483-87981772c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(zip(features, masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f036cb14-0151-4b58-8fc8-9d5fc1164a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, labels_resampled = ros.fit_resample(X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97abf6cc-917f-417d-b3a9-8a41e761aa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_resampled, masks_resampled = list(zip(*X_resampled))\n",
    "\n",
    "features_resampled = np.array([np.array(xi) for xi in features_resampled])\n",
    "masks_resampled = np.array([np.array(xi) for xi in masks_resampled])\n",
    "\n",
    "print(features_resampled.shape)\n",
    "print(masks_resampled.shape)\n",
    "print(labels_resampled.shape)\n",
    "\n",
    "features = torch.tensor(features_resampled, dtype=torch.float).to(device)\n",
    "masks = torch.tensor(masks_resampled, dtype=torch.float).to(device)\n",
    "labels = torch.tensor(labels_resampled, dtype=torch.float).to(device)\n",
    "\n",
    "print(features.shape)\n",
    "print(masks.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab338ea2-8610-40ed-87aa-210e368df325",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_masks, test_masks, train_labels, test_labels = train_test_split(features, masks, labels, test_size=0.1, random_state=42)\n",
    "train_features, validation_features, train_masks, validation_masks, train_labels, validation_labels = train_test_split(train_features, train_masks, train_labels, test_size=0.1, random_state=42)\n",
    "\n",
    "def create_easy_train_dataloader(model, N, K, epoch):\n",
    "    easy_timeseries, easy_masks, easy_labels = pick_easy_tasks(model, train_features, train_masks, train_labels, N, K, epoch)\n",
    "    easy_train_dataset = TensorDataset(easy_timeseries, easy_masks, easy_labels)\n",
    "    if len(easy_train_dataset) == 0:\n",
    "        return None, len(train_features)\n",
    "    return DataLoader(easy_train_dataset, batch_size=32, shuffle=True), len(train_features)\n",
    "\n",
    "test_dataset = TensorDataset(test_features, test_masks, test_labels)\n",
    "validation_dataset = TensorDataset(validation_features, validation_masks, validation_labels)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=len(validation_dataset), shuffle=False)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_features)} ICU stays with 48-hour timeseries for {features.size()[2]} measurements each\")\n",
    "print(f\"Test dataset size: {len(test_dataset)} ICU stays with 48-hour timeseries for {features.size()[2]} measurements each\")\n",
    "print(f\"Validation dataset size: {len(validation_dataset)} ICU stays with 48-hour timeseries for {features.size()[2]} measurements each\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacdfe67-c25f-4bf9-9f0f-6b6137173db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "constant_classifier = DummyClassifier(strategy=\"constant\", constant=1)\n",
    "uniform_classifier = DummyClassifier(strategy=\"uniform\")\n",
    "\n",
    "inputs, labels = None, None\n",
    "for inp, mask, lab in validation_dataloader:\n",
    "    inputs, labels = inp, lab\n",
    "    labels = labels.clone().cpu().detach()\n",
    "\n",
    "constant_classifier.fit([0] * len(labels), labels)\n",
    "uniform_classifier.fit([0] * len(labels), labels)\n",
    "y_constant = constant_classifier.predict([0] * len(labels))\n",
    "y_uniform = uniform_classifier.predict([0] * len(labels))\n",
    "\n",
    "print(f\"Baseline F1 score constant 1: {f1_score(labels, y_constant)}\")\n",
    "print(f\"Baseline F1 score uniform: {f1_score(labels, y_uniform)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd26fc87-1982-4e16-9f41-142e0c57d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.5\n",
    "N = 16\n",
    "LAMBDA = 1.3\n",
    "LR = 0.001\n",
    "OMEGA = 0.001\n",
    "K = 1\n",
    "TOLERANCE = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48d7e17-b9bb-41f0-b4f4-73e8dda0a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn\n",
    "\n",
    "class TinyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "        self.rnn = nn.GRU(input_size=104, hidden_size=32, num_layers=1, bidirectional=False, batch_first=True)\n",
    "        self.fc1 = nn.Linear(in_features=32, out_features=1)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        try:\n",
    "            x = x * mask\n",
    "        except:\n",
    "            print(x, mask)\n",
    "        _, h_n = self.rnn(x)\n",
    "        fc1_out = self.fc1(torch.squeeze(h_n))\n",
    "        # Multiply prediction value before sigmoid activation by gamma.\n",
    "        # This is part of the micro framework.\n",
    "        r = torch.mul(fc1_out, GAMMA)\n",
    "        res = torch.sigmoid(r)\n",
    "        return torch.squeeze(res)\n",
    "\n",
    "tinymodel = TinyModel()\n",
    "tinymodel.to(device)\n",
    "\n",
    "print('The model:')\n",
    "print(tinymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae80b486-c86a-41e7-947c-87afbf624ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(tinymodel.parameters(), LR)\n",
    "\n",
    "def loss_func(y_hat, y, model):\n",
    "    # Add a dimension when there is only one item in the batch.     \n",
    "    if len(y_hat.size()) == 0:\n",
    "        y_hat = torch.unsqueeze(y_hat, dim=0)\n",
    "\n",
    "    l1 = OMEGA * sum(p.abs().sum() for p in model.parameters())\n",
    "    cr = (1 / GAMMA) * criterion(y_hat, y)\n",
    "    \n",
    "    # Calculate the loss. The regularization is just an l1 regularization with a coefficient.\n",
    "    # The criterion is the binary cross-entropy multiplied by 1 / GAMMA, a part of the micro framework.\n",
    "    return l1 + cr\n",
    "\n",
    "    # The paper also says to subtract batch_size / N, but this value is different for different batches depending\n",
    "    # on the number of easy tasks in the batch, making it hard to compare loss across batches. Crucially, this \n",
    "    # is confusing when you look at the loss on training data (non-full batches) vs loss on testing data (full-size batches).\n",
    "    # This makes me think that actually the paper meant that you first pick easy tasks across the entire testing set,\n",
    "    # and then split it into batches rather than split into batches first and pick easy tasks after.\n",
    "#     batch_size = y_hat.size()[0]    \n",
    "#     neg = batch_size / N\n",
    "#     return l1 + cr - neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1ea2c4-ff8c-4aec-a221-2a32c9f9b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement early stopping\n",
    "\n",
    "previous_loss = 1e10\n",
    "\n",
    "for epoch in range(100):\n",
    "    running_loss = 0.0\n",
    "    number_examples_used = 0\n",
    "    dataloader, max_num_examples = create_easy_train_dataloader(tinymodel, N, K, epoch)\n",
    "    \n",
    "    if dataloader is not None:\n",
    "        for i, (features, masks, labels) in enumerate(dataloader):\n",
    "            tinymodel.train(True)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Train on easy sequences.\n",
    "            output = tinymodel(features, masks)\n",
    "            loss = loss_func(output, labels, tinymodel)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            number_examples_used += len(features)\n",
    "            if (i + 1) % 50 == 0:\n",
    "                print(f'Epoch: [{epoch + 1}, training batch {i + 1:5d}] running training loss: {running_loss / 50:.3f}')\n",
    "                running_loss = 0.0\n",
    "    \n",
    "    running_test_loss = 0.0\n",
    "    tinymodel.train(False)\n",
    "    print(f\"In epoch {epoch + 1}, number of examples trained on is {number_examples_used} out of {max_num_examples}\")\n",
    "    for i, (test_inputs, test_masks, test_labels) in enumerate(test_dataloader):\n",
    "        test_outputs = tinymodel(test_inputs, test_masks)\n",
    "        test_loss = loss_func(test_outputs, test_labels, tinymodel)\n",
    "        running_test_loss += test_loss\n",
    "    \n",
    "    normalized_running_test_loss = running_test_loss / len(test_dataloader)\n",
    "    print(f\"Test loss: {normalized_running_test_loss}\")\n",
    "    \n",
    "    if previous_loss - normalized_running_test_loss < TOLERANCE and epoch > 20:\n",
    "        print(f\"Early stopping, as {previous_loss - normalized_running_test_loss} < {TOLERANCE}\")\n",
    "        break\n",
    "    \n",
    "    previous_loss = normalized_running_test_loss\n",
    "    \n",
    "    # Once we have passed K warm-up epochs, decrease N by a factor of lambd\n",
    "    # and as such increase 1 / N, so increase the loss threshold that defines\n",
    "    # what tasks are considrered easy.\n",
    "    if epoch >= K:\n",
    "        N = N / LAMBDA\n",
    "    print(f\"N is now {N}\\n\\n\")\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6592c29c-748d-4424-8949-8fb5c0df3a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "tinymodel.train(False)\n",
    "out = None\n",
    "lab = None\n",
    "for inputs, masks, labels in validation_dataloader:\n",
    "    outputs = tinymodel(inputs, masks)\n",
    "    out = outputs\n",
    "    outputs = outputs > 0.5\n",
    "    lab = labels\n",
    "    labels = labels.detach().cpu().numpy()\n",
    "    outputs = outputs.detach().cpu().numpy()\n",
    "    print(f\"F1 score: {f1_score(labels, outputs)}\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(labels, outputs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51e6675-004d-44e8-9554-4a838774891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "# Fill with real values\n",
    "preds = out.cpu().detach().numpy()\n",
    "\n",
    "def mean(x):\n",
    "    return sum(x) / len(x)\n",
    "\n",
    "coverages = []\n",
    "calculated_metrics = []\n",
    "    \n",
    "criterion = nn.BCELoss(reduction='none')\n",
    "loss = (1 / GAMMA) * criterion(out, lab)\n",
    "ordered_indices = torch.argsort(loss)\n",
    "ordered_outputs = 1.0 * (torch.index_select(out, 0, ordered_indices))\n",
    "ordered_labels = torch.index_select(lab, 0, ordered_indices)\n",
    "\n",
    "ordered_outputs = ordered_outputs.cpu().detach().numpy()\n",
    "ordered_labels = ordered_labels.cpu().detach().numpy()\n",
    "\n",
    "AUC = 0\n",
    "\n",
    "for coverage in np.arange(0, 1.005, 0.01):\n",
    "    length = len(ordered_outputs)\n",
    "    cutoff_index = int(length * coverage) + 1\n",
    "    \n",
    "    included_outputs = ordered_outputs[0:cutoff_index]\n",
    "    included_labels = ordered_labels[0:cutoff_index]\n",
    "    \n",
    "    if sum(included_labels) == 0 or sum(included_outputs) == 0 or sum(included_labels) == cutoff_index or sum(included_outputs) == cutoff_index:\n",
    "        print(coverage)\n",
    "        continue\n",
    "\n",
    "    metric = metrics.roc_auc_score(included_labels, included_outputs)\n",
    "    calculated_metrics.append(metric)\n",
    "    coverages.append(coverage)\n",
    "    \n",
    "    AUC += metric * 0.01\n",
    "    \n",
    "plt.plot(coverages, calculated_metrics)\n",
    "# plt.ylim(-0.1, 1.1)\n",
    "plt.show()\n",
    "print(f\"Area under the metric-coverage plot: {AUC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809bca14-de0c-4abc-ae57-951a28e8ea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calculated_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5849a2f-8ac8-4a26-ab95-3212a5395a69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-dl4h-39]",
   "language": "python",
   "name": "conda-env-.conda-dl4h-39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
