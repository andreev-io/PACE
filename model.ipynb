{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7635ebcf-72d0-4401-a8f1-30c209378284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import datetime\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63172a0b-e8d6-4334-a41d-7d49155b9f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca607a3-4d07-4e3e-8f40-c65c2afd40e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cac9b9-7b0a-41b1-8216-b0e4e852d452",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/lvl2_train.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f).sort_values(['subject_id', 'hadm_id', 'icustay_id'])\n",
    "\n",
    "with open(\"data/Ys_train.pkl\", \"rb\") as f:\n",
    "    labels = pickle.load(f).sort_values(['subject_id', 'hadm_id', 'icustay_id'])\n",
    "    \n",
    "data = data.reset_index(drop=True).droplevel(level=\"LEVEL2\", axis=1)\n",
    "features = data[\"mean\"].to_numpy()\n",
    "masks = data[\"mask\"].to_numpy()\n",
    "\n",
    "features = np.split(features, [48 * i for i in range(1, len(features) // 48)])\n",
    "masks = np.split(masks, [48 * i for i in range(1, len(masks) // 48)])\n",
    "\n",
    "features = torch.tensor(features, dtype=torch.float).to(device)\n",
    "masks = torch.tensor(masks, dtype=torch.float).to(device)\n",
    "labels = torch.squeeze(torch.tensor(labels.to_numpy(), dtype=torch.float).to(device))\n",
    "\n",
    "print(f\"Shape of features: {features.size()}\")\n",
    "print(f\"Shape of masks: {masks.size()}\")\n",
    "print(f\"Shape of labels: {labels.size()}\")\n",
    "assert len(features) == len(labels)\n",
    "assert features.size() == masks.size()\n",
    "\n",
    "d = TensorDataset(features, masks, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab338ea2-8610-40ed-87aa-210e368df325",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset size: {len(features)} ICU stays with 48-hour timeseries for {features.size()[2]} measurements each\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a4048b-a691-4ea6-8bfd-8507961d33a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    " \n",
    "splits = [int(round(len(d) * 8 / 10)), int(round(len(d) / 10)), int(round(len(d) / 10))]\n",
    "train_data, test_data, validation_data = random_split(d, splits, torch.Generator())\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=len(validation_data), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacdfe67-c25f-4bf9-9f0f-6b6137173db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "constant_classifier = DummyClassifier(strategy=\"constant\", constant=1)\n",
    "uniform_classifier = DummyClassifier(strategy=\"uniform\")\n",
    "\n",
    "inputs, labels = None, None\n",
    "for inp, mask, lab in validation_dataloader:\n",
    "    inputs, labels = inp, lab\n",
    "    labels = labels.clone().cpu().detach()\n",
    "\n",
    "constant_classifier.fit([0] * len(labels), labels)\n",
    "uniform_classifier.fit([0] * len(labels), labels)\n",
    "y_constant = constant_classifier.predict([0] * len(labels))\n",
    "y_uniform = uniform_classifier.predict([0] * len(labels))\n",
    "\n",
    "print(f\"Baseline F1 score constant 1: {f1_score(labels, y_constant)}\")\n",
    "print(f\"Baseline F1 score uniform: {f1_score(labels, y_uniform)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd26fc87-1982-4e16-9f41-142e0c57d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.5\n",
    "N = 16\n",
    "LAMBDA = 1.3\n",
    "LR = 0.001\n",
    "OMEGA = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48d7e17-b9bb-41f0-b4f4-73e8dda0a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn\n",
    "\n",
    "class TinyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "        self.rnn = nn.GRU(input_size=104, hidden_size=32, num_layers=1, bidirectional=False, batch_first=True)\n",
    "        self.fc1 = nn.Linear(in_features=32, out_features=1)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        try:\n",
    "            x = x * mask\n",
    "        except:\n",
    "            print(x, mask)\n",
    "        _, h_n = self.rnn(x)\n",
    "        fc1_out = self.fc1(torch.squeeze(h_n))\n",
    "        # Multiply prediction value before sigmoid activation by gamma.\n",
    "        # This is part of the micro framework.\n",
    "        r = torch.mul(fc1_out, GAMMA)\n",
    "        res = torch.sigmoid(r)\n",
    "        return torch.squeeze(res)\n",
    "\n",
    "tinymodel = TinyModel()\n",
    "tinymodel.to(device)\n",
    "\n",
    "print('The model:')\n",
    "print(tinymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae80b486-c86a-41e7-947c-87afbf624ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(tinymodel.parameters(), LR)\n",
    "\n",
    "def loss_func(y_hat, y, model):\n",
    "    # Add a dimension when there is only one item in the batch.     \n",
    "    if len(y_hat.size()) == 0:\n",
    "        y_hat = torch.unsqueeze(y_hat, dim=0)\n",
    "\n",
    "    l1 = OMEGA * sum(p.abs().sum() for p in model.parameters())\n",
    "    cr = (1 / GAMMA) * criterion(y_hat, y)\n",
    "    \n",
    "    # Calculate the loss. The regularization is just an l1 regularization with a coefficient.\n",
    "    # The criterion is the binary cross-entropy multiplied by 1 / GAMMA, a part of the micro framework.\n",
    "    return l1 + cr\n",
    "\n",
    "    # The paper also says to subtract batch_size / N, but this value is different for different batches depending\n",
    "    # on the number of easy tasks in the batch, making it hard to compare loss across batches. Crucially, this \n",
    "    # is confusing when you look at the loss on training data (non-full batches) vs loss on testing data (full-size batches).\n",
    "    # This makes me think that actually the paper meant that you first pick easy tasks across the entire testing set,\n",
    "    # and then split it into batches rather than split into batches first and pick easy tasks after.\n",
    "    # batch_size = y_hat.size()[0]    \n",
    "    # neg = batch_size / N\n",
    "    # return l1 + cr - neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21b5d56-f275-41e9-8f83-721a35783f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_easy_tasks(model, x, mask, y, N):\n",
    "    criterion = nn.BCELoss(reduction='none')\n",
    "    model.train(False)\n",
    "    y_hat = model(x, mask)\n",
    "\n",
    "    # Pick tasks in the batch for which the loss is less than 1 / N.\n",
    "    loss = torch.add((1 / GAMMA) * criterion(y_hat, y), -1 / N)\n",
    "    easy_indices = list((loss < 0).nonzero())\n",
    "\n",
    "    easy_timeseries = torch.empty((len(easy_indices), x.size()[1], x.size()[2]))\n",
    "    easy_masks = torch.empty((len(easy_indices), x.size()[1], x.size()[2]))\n",
    "    easy_labels = torch.empty((len(easy_indices),))\n",
    "\n",
    "    for i, index in enumerate(easy_indices):\n",
    "        index = index.item()\n",
    "        easy_timeseries[i] = x[index]\n",
    "        easy_masks[i] = mask[index]\n",
    "        easy_labels[i] = y[index]\n",
    "\n",
    "    model.train(True)\n",
    "    return torch.Tensor(easy_timeseries).to(device), torch.Tensor(easy_masks).to(device), torch.Tensor(easy_labels).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1ea2c4-ff8c-4aec-a221-2a32c9f9b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement early stopping\n",
    "for epoch in range(40):\n",
    "    running_loss = 0.0\n",
    "    number_examples_used = 0\n",
    "    num_examples = 0\n",
    "    for i, (features, masks, labels) in enumerate(train_dataloader):\n",
    "        num_examples = num_examples + len(features)\n",
    "        tinymodel.train(True)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Pick easy sequences with the current N. If no sequences are easy, skip the batch.\n",
    "        easy_timeseries, easy_masks, easy_labels = pick_easy_tasks(tinymodel, features, masks, labels, N)\n",
    "        if len(easy_timeseries) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            number_examples_used = number_examples_used + len(easy_timeseries)\n",
    "\n",
    "        # Train on easy sequences.\n",
    "        easy_output = tinymodel(easy_timeseries, easy_masks)\n",
    "        loss = loss_func(easy_output, easy_labels, tinymodel)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f'Epoch: [{epoch + 1}, training batch {i + 1:5d}] running training loss: {running_loss / 50:.3f}')\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    running_test_loss = 0.0\n",
    "    tinymodel.train(False)\n",
    "    print(f\"In epoch {epoch + 1}, number of examples trained on is {number_examples_used} out of {num_examples}\")\n",
    "    for i, (test_inputs, test_masks, test_labels) in enumerate(test_dataloader):\n",
    "        test_outputs = tinymodel(test_inputs, test_masks)\n",
    "        test_loss = loss_func(test_outputs, test_labels, tinymodel)\n",
    "        running_test_loss += test_loss\n",
    "    \n",
    "    print(f\"Test loss: {running_test_loss / len(test_dataloader)}\")\n",
    "    # Decrease N by a factor of lambda and as such increase 1 / N, so increase the loss threshold that defines\n",
    "    # what tasks are considrered easy.\n",
    "    N = N / LAMBDA\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6592c29c-748d-4424-8949-8fb5c0df3a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "tinymodel.train(False)\n",
    "out = None\n",
    "lab = None\n",
    "for inputs, masks, labels in validation_dataloader:\n",
    "    outputs = tinymodel(inputs, masks)\n",
    "    out = outputs\n",
    "    outputs = outputs > 0.5\n",
    "    lab = labels\n",
    "    labels = labels.detach().cpu().numpy()\n",
    "    outputs = outputs.detach().cpu().numpy()\n",
    "    print(f\"F1 score: {f1_score(labels, outputs)}\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(labels, outputs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b51e6675-004d-44e8-9554-4a838774891b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137.0\n",
      "1559\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "# Fill with real values\n",
    "preds = out.cpu().detach().numpy()\n",
    "true_labels = lab.cpu().detach().numpy()\n",
    "print(sum(true_labels))\n",
    "print(len(true_labels))\n",
    "\n",
    "confidence = 0.5 + abs(preds - 0.5)\n",
    "\n",
    "def mean(x):\n",
    "    return sum(x) / len(x)\n",
    "\n",
    "coverages = []\n",
    "calculated_metrics = []\n",
    "\n",
    "for confidence_treshold in np.arange(0.5, 1.00000000, 0.01):\n",
    "    predicted_labels = 1.0 * (preds > 0.5)\n",
    "    \n",
    "    replace_mask = confidence < confidence_treshold\n",
    "    predicted_labels[replace_mask] = 0\n",
    "\n",
    "    coverage = mean(1.0 * (confidence > confidence_treshold))\n",
    "\n",
    "    if len(true_labels[replace_mask]) == 0 or sum(predicted_labels) == 0:\n",
    "        continue\n",
    "\n",
    "    auc = metrics.roc_auc_score(true_labels[~replace_mask], predicted_labels[~replace_mask])\n",
    "    \n",
    "    calculated_metrics.append(auc)\n",
    "    coverages.append(coverage)\n",
    "    \n",
    "plt.plot(coverages, calculated_metrics)\n",
    "plt.ylim(0, 1) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "809bca14-de0c-4abc-ae57-951a28e8ea7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9967928159076331, 0.994868505452213, 0.9916613213598461, 0.9897370109044259, 0.9871712636305324, 0.9820397690827454, 0.9801154586273252, 0.9749839640795381, 0.9717767799871713, 0.967928159076331, 0.962796664528544, 0.9602309172546504, 0.9570237331622835, 0.9525336754329699, 0.9480436177036562, 0.9416292495189224, 0.9332905708787684, 0.9288005131494548, 0.9255933290570879, 0.9230275817831943, 0.9178960872354073, 0.9134060295060936, 0.90891597177678, 0.9069916613213599, 0.9025016035920462, 0.895445798588839, 0.8928800513149455, 0.8890314304041051, 0.8858242463117383, 0.881975625400898, 0.8774855676715844, 0.868505452212957, 0.8614496472097498, 0.8569595894804362, 0.8505452212957024, 0.8460551635663887, 0.8351507376523413, 0.8248877485567672, 0.8184733803720333, 0.8069275176395125]\n"
     ]
    }
   ],
   "source": [
    "print(coverages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61cfcea-38cd-430b-b2f4-dcafd2d95176",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-mimic-extract-2]",
   "language": "python",
   "name": "conda-env-.conda-mimic-extract-2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
